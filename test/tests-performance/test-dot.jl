#-------------------------Threads  

function dot_threads(SIZE, x, y)
    tmp = zeros(Threads.nthreads())
    ret = zeros(1)
    Threads.@threads for i in 1:SIZE
        tmp[Threads.threadid()] = tmp[Threads.threadid()] .+ x[i] * y[i]
    end
    for i in 1:Threads.nthreads()
        ret = ret .+ tmp[i]
    end
    return ret
end

SIZE = 1000000
x = ones(SIZE)
y = ones(SIZE)
@time begin
    dot_threads(SIZE, x, y)
end

#-------------------------CUDA

function dot_cuda_kernel(SIZE, ret, x, y)
    shared_mem = @cuDynamicSharedMem(Float64, 512)
    i = (blockIdx().x - 1) * blockDim().x + threadIdx().x
    ii = i
    tmp::Float64 = 0.0
    if SIZE > 512
        while ii <= SIZE
            tmp += @inbounds x[ii] * y[ii]
            ii += 512
        end
    else
        tmp = @inbounds x[i] * y[i]
    end
    shared_mem[i] = tmp
    sync_threads()
    if (i <= 256)
        shared_mem[i] += shared_mem[i + 256]
    end
    sync_threads()
    if (i <= 128)
        shared_mem[i] += shared_mem[i + 128]
    end
    sync_threads()
    if (i <= 64)
        shared_mem[i] += shared_mem[i + 64]
    end
    sync_threads()
    if (i <= 32)
        shared_mem[i] += shared_mem[i + 32]
    end
    sync_threads()
    if (i <= 16)
        shared_mem[i] += shared_mem[i + 16]
    end
    sync_threads()
    if (i <= 8)
        shared_mem[i] += shared_mem[i + 8]
    end
    sync_threads()
    if (i <= 4)
        shared_mem[i] += shared_mem[i + 4]
    end
    sync_threads()
    if (i <= 2)
        shared_mem[i] += shared_mem[i + 2]
    end
    sync_threads()
    if (i == 1)
        shared_mem[i] += shared_mem[i + 1]
        ret[1] = shared_mem[1]
    end
    return nothing
end

function dot_cuda(SIZE, x, y)
    maxPossibleThreads = 512
    threads = min(SIZE, maxPossibleThreads)
    ret = CUDA.zeros(1)
    CUDA.@sync @cuda threads=threads blocks=1 shmem=512 * sizeof(Float64) dot_cuda_kernel(
        SIZE, ret, x, y)
    return ret[1]
end

SIZE = 10000000
x = ones(SIZE)
y = ones(SIZE)
dx = CuArray(x)
dy = CuArray(y)
@time begin
    res = dot_cuda(SIZE, dx, dy)
end

#-------------------------AMDGPU

function dot_amdgpu_kernel(SIZE, ret, x, y)
    shared_mem = @ROCDynamicLocalArray(Float64, 1024)
    i = (workgroupIdx().x - 1) * workgroupDim().x + workitemIdx().x
    ii = i
    tmp::Float64 = 0.0
    if SIZE > 1024
        while ii <= SIZE
            tmp += @inbounds x[ii] * y[ii]
            ii += 1024
        end
    else
        tmp = @inbounds x[i] * y[i]
    end
    shared_mem[i] = tmp
    AMDGPU.sync_workgroup()
    if (i <= 512)
        shared_mem[i] += shared_mem[i + 512]
    end
    AMDGPU.sync_workgroup()
    if (i <= 256)
        shared_mem[i] += shared_mem[i + 256]
    end
    AMDGPU.sync_workgroup()
    if (i <= 128)
        shared_mem[i] += shared_mem[i + 128]
    end
    AMDGPU.sync_workgroup()
    if (i <= 64)
        shared_mem[i] += shared_mem[i + 64]
    end
    AMDGPU.sync_workgroup()
    if (i <= 32)
        shared_mem[i] += shared_mem[i + 32]
    end
    AMDGPU.sync_workgroup()
    if (i <= 16)
        shared_mem[i] += shared_mem[i + 16]
    end
    AMDGPU.sync_workgroup()
    if (i <= 8)
        shared_mem[i] += shared_mem[i + 8]
    end
    AMDGPU.sync_workgroup()
    if (i <= 4)
        shared_mem[i] += shared_mem[i + 4]
    end
    AMDGPU.sync_workgroup()
    if (i <= 2)
        shared_mem[i] += shared_mem[i + 2]
    end
    AMDGPU.sync_workgroup()
    if (i == 1)
        shared_mem[i] += shared_mem[i + 1]
        ret[1] = shared_mem[1]
    end
    return nothing
end

function dot_amdgpu(SIZE, x, y)
    maxPossibleThreads = 1024
    threads = min(SIZE, maxPossibleThreads)
    ret = AMDGPU.zeros(1)
    @roc groupsize=threads gridsize=threads localmem=1024 * sizeof(Float64) dot_amdgpu_kernel(
        SIZE, ret, x, y)
    return ret[1]
end

SIZE = 10000000
x = ones(SIZE)
y = ones(SIZE)
dx = ROCArray(x)
dy = ROCArray(y)
@time begin
    res = dot_amdgpu(SIZE, dx, dy)
end

#-------------------------oneAPI

function dot_oneapi_kernel(SIZE, ret, x, y)
    shared_mem = oneLocalArray(Float32, 256)
    i = get_global_id()
    ii = i
    tmp::Float32 = 0.0
    if SIZE > 256
        while ii <= SIZE
            tmp += @inbounds x[ii] * y[ii]
            ii += 256
        end
    else
        tmp = @inbounds x[i] * y[i]
    end
    shared_mem[i] = tmp
    barrier()
    if (i <= 128)
        shared_mem[i] += shared_mem[i + 128]
    end
    barrier()
    if (i <= 64)
        shared_mem[i] += shared_mem[i + 64]
    end
    barrier()
    if (i <= 32)
        shared_mem[i] += shared_mem[i + 32]
    end
    barrier()
    if (i <= 16)
        shared_mem[i] += shared_mem[i + 16]
    end
    barrier()
    if (i <= 8)
        shared_mem[i] += shared_mem[i + 8]
    end
    barrier()
    if (i <= 4)
        shared_mem[i] += shared_mem[i + 4]
    end
    barrier()
    if (i <= 2)
        shared_mem[i] += shared_mem[i + 2]
    end
    barrier()
    if (i == 1)
        shared_mem[i] += shared_mem[i + 1]
        ret[1] = shared_mem[i]
    end
    return nothing
end

function dot_oneapi(SIZE, x, y)
    numItems = 256
    items = min(SIZE, numItems)
    ret = oneAPI.zeros(Float32, 1)
    oneAPI.@sync @oneapi items=items groups=1 dot_oneapi_kernel(SIZE, ret, x, y)
    #oneAPI.@sync @oneapi items = items groups = 1 dot_oneapi_kernel(SIZE, x, y)
    return ret[1]
end

SIZE = 100000000
x = ones(Float32, SIZE)
y = ones(Float32, SIZE)
dx = oneArray(x)
dy = oneArray(y)
@time begin
    res = dot_oneapi(SIZE, dx, dy)
end

#-------------------------JACC

function dot(i, x, y)
    return @inbounds x[i] * y[i]
end

SIZE = 100000000
x = ones(SIZE)
y = ones(SIZE)
jx = JACC.Array(x)
jy = JACC.Array(y)
@time begin
    res = JACC.parallel_reduce(SIZE, dot, jx, jy)
end

function dot(i, x, y)
    return @inbounds x[i] * y[i]
end

SIZE = 100000000
x = ones(Float32, SIZE)
y = ones(Float32, SIZE)
jx = JACC.Array(x)
jy = JACC.Array(y)
@time begin
    res = JACC.parallel_reduce(SIZE, dot, jx, jy)
end
