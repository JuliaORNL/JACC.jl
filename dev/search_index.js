var documenterSearchIndex = {"docs":
[{"location":"miscellaneous/#Acknowledgements","page":"Miscellaneous","title":"Acknowledgements","text":"JACC is funded by the US Department of Energy Advanced Scientific Computing Research (ASCR) projects:\n\nS4PST as part of the Next Generation of Scientific Software Technologies (NGSST) ASCR Program. \nNGSST sponsors the Consortium for the Advancement of Scientific Software, CASS\nASCR Competitive Portfolios for Advanced Scientific Computing Research, MAGMA/Fairbanks\n\nFormer sponsors:\n\nASCR Bluestone X-Stack\nThe Exascale Computing Project - PROTEAS-TUNE \n\nJACC would not be possible without the contributions of the Julia language and the JuliaGPU community and the amazing GPU work of the CUDA.jl, AMDGPU.jl, oneAPI.jl and Metal.jl backend developers.","category":"section"},{"location":"miscellaneous/#Citing-JACC","page":"Miscellaneous","title":"Citing JACC","text":"Much of JACC is motivated by the Julia desire to make high-performance computing more accessible to a broader range of users. If you use JACC in your research or projects, we would appreciate it if you could cite our paper from SC24-WAACPD, open version available here.\n\nbib entry:\n\n@INPROCEEDINGS{JACC,\n  author={Valero-Lara, Pedro and Godoy, William F and Mankad, Het and Teranishi, Keita and Vetter, Jeffrey S and Blaschke, Johannes and Schanen, Michel},\n  booktitle={Proceedings of the SC '24 Workshops of The International Conference on High Performance Computing, Network, Storage, and Analysis},\n  title={{JACC: Leveraging HPC Meta-Programming and Performance Portability with the Just-in-Time and LLVM-based Julia Language}},\n  year={2024},\n  volume={},\n  number={},\n  pages={},\n  doi={10.1109/SCW63240.2024.00245}\n}\n\nOther papers that contributed to JACC's exploratory research include:\n\nJACC shared at IEEE HPEC\nJACC Multi-GPU IEEE eScience","category":"section"},{"location":"miscellaneous/#License","page":"Miscellaneous","title":"License","text":"JACC.jl is licensed under the permissive MIT License, UT-BATTELLE, LLC owns the Copyright. See the LICENSE file for details. We will remain open-source and welcome contributions from the community.","category":"section"},{"location":"miscellaneous/#Frequently-Asked-Questions","page":"Miscellaneous","title":"Frequently Asked Questions","text":"How does JACC differ from other Julia GPU programming packages?\nJACC focuses on providing a high-level, backend-agnostic API for parallel computing that abstracts away the complexities of different CPU/GPU architectures. It leverages Julia's metaprogramming capabilities to offer a unified interface for various backends, making it easier for developers to write portable code without having to learn the nuances of each backend or GPU programming model. Hence, JACC.jl is complimentary to existing programming models in the Julia ecosystem and targets the needs of users seeking a unified, portable approach for HPC codes. We invite users to explore the JuliaGPU ecosystem for more specialized GPU programming needs. One important thing to note is that JACC is not a new backend itself but rather a layer on top of existing backends like CUDA.jl, AMDGPU.jl, Metal.jl, and oneAPI.jl. We welcome collaborations with other JuliaGPU backend developers to ensure compatibility and leverage their strengths.\nWhat is the performance overhead of using JACC compared to writing backend-specific code?\nWhile JACC introduces some abstraction layers, it is designed to minimize performance overhead. The just-in-time (JIT) compilation and LLVM-based optimizations in Julia help ensure that the generated code is efficient. Our SC24-WAACPD paper includes performance benchmarks demonstrating that JACC can achieve performance comparable to backend-specific implementations for many workloads. However, for highly specialized or performance-critical applications, users may still choose to write backend-specific code when necessary. This is ongoing exploratory research with actual science applications, see JACC-applications.\nWho uses JACC?\nJACC is primarily targeted at scientists, engineers, and researchers. We thank the early adopters for their feedback, in particular CERFACS, the University of Tokyo, Riken FugakuNext programming environments,the New Jersey Institute of Technology and Oak Ridge National Laboratory (where it originates) and anyone adopting Julia for their scietific computing capabilities. We aim to grow this community further. If you are using JACC in your projects, please let us know! We would love to hear about your experiences and use cases.\nWhat's JACC's governance model?\nJACC is open-source software hosted on GitHub funded primarily by the US Department of Energy for HPC science needs with the core development done at ORNL. Hence, our roadmap is driven by both community needs and the evolving landscape of HPC and GPU computing. We welcome contributions from the community, including bug reports, feature requests, and code contributions. The core development team at ORNL oversees the project's direction, but we encourage collaboration and input from users and contributors worldwide. Open an issue on GitHub to get involved.","category":"section"},{"location":"api_usage/#API-components","page":"API Usage","title":"API components","text":"JACC APIs consist of three main components:\n\nBackend selection: e.g. JACC.set_backend(\"CUDA\") (outside user code) and JACC.@init_backend (inside user code)\nMemory allocation: e.g. JACC.array{T}(), JACC.zeros, JACC.ones, JACC.shared, JACC.Multi\nKernel launching: e.g. JACC.@parallel_for and JACC.@parallel_reduce (along with functions for JACC.parallel_for and JACC.parallel_reduce)","category":"section"},{"location":"api_usage/#Backend-selection","page":"API Usage","title":"Backend selection","text":"JACC.set_backend: allows selecting the runtime backend on CPU: Threads (default) and GPU: CUDA, AMDGPU, oneAPI. Uses Preferences.jl and stores the selected backend in a LocalPreferences.jl file if JACC.jl is a project dependency. Use JACC.set_backend prior to running any code targeting a particular backend.\n\nExample:\n\nusing JACC\nJACC.set_backend(\"CUDA\")\n\nor from the command line (e.g. in CI workflows):\n\n$ julia -e 'using JACC; JACC.set_backend(\"CUDA\")'\n\ndanger: Danger\nset_backend will polute your project's Project.toml adding the selected backend package. Beware of committing this change (e.g. during development). To clean up, you can run JACC.unset_backend() or manually edit your local Project.toml file.\n\nwarning: Warning\nThis step might take a while the very first time downloading all backend dependencies. \n\ntip: Tip for CUDA\nCUDA.jl uses its own prebuilt CUDA stack by default, please refer to CUDA.jl docs if wanting to use a local CUDA installation to set up LocalPreferences.toml. \n\ntip: Tip for AMDGPU\nAMDGPU.jl relies on standard rocm installation under /opt/rocm, for non-standard locations set the environment variable ROCM_PATH, see docs.\n\nJACC.@init_backend: initializes the selected back end automatically from LocalPreferences.toml from JACC.set_backend. JACC.@init_backend should be used in your code before using any JACC.jl functionality. Recent improvements have made this process more seamless.\n\nExample:\n\nusing JACC\nJACC.@init_backend\n\ntip: Always use `JACC.@init_backend`\nUse JACC.@init_backend right after import JACC or using JACC for portable backend-agnostic code.","category":"section"},{"location":"api_usage/#Memory-allocation","page":"API Usage","title":"Memory allocation","text":"JACC.array{T}(): create a new array on the device with the specified type and size.\nJACC.zeros: create a new array on the device filled with zeros.\nJACC.ones: create a new array on the device filled with ones.\nJACC.fill: create a new array on the device filled with a specified value.\nJACC.to_device: transfer an existing Julia array from host to device.\nJACC.to_host: transfer an existing JACC array from device to host.\n\nAdvanced memory:\n\nJACC.Multi module: allows the programmability of multiple-GPU devices on a single node without the need of MPI. Please see the paper Valero-Lara et al. IEEE eScience 2025 \nJACC.shared: exploits fast-access cache memory on device. Use it inside kernel functions. Please see the paper Valero-Lara IEEE HPEC 2024 for more details.\nJACC.@atomic: creates an atomic operation for safe concurrent access. Use it inside kernel functions. Wraps @atomic from the supported Atomix.jl package in the JuliaGPU ecosystem. Careful must be taken as atomic operations can be costly in terms of performance.","category":"section"},{"location":"api_usage/#Kernel-launching","page":"API Usage","title":"Kernel launching","text":"JACC provides two main macros/functions to launch parallel workloads on the selected back end: JACC.@parallel_for/parallel_for and JACC.@parallel_reduce/parallel_reduce.\n\nJACC.@parallel_for/parallel_for: launch a parallel for loop (each i index is independent) running a \"kernel\" workload function with variadic arguments. \n\nJACC.@parallel_reduce/parallel_reduce: launch a parallel reduce operation running a \"kernel\" workload function with variadic arguments.\n\ntip: macro vs function\nThe preferred way is to use the macros @parallel_for and @parallel_reduce as they provide a more expressive syntax separating kernel definitions (e.g., computational science) from optional launch parameters (e.g., computer science) for readability. It follows closer Julia's rich metaprogramming philosophy from Lisp.\n\ntip: `parallel_reduce` convenience functions\nOptionally, the parallel_reduce function provides convenient simplified overloads for common reduction operations, e.g., x_sum = JACC.parallel_reduce(x) computes the sum of all elements in array x.","category":"section"},{"location":"api_usage/#Basic-kernel-launching","page":"API Usage","title":"Basic kernel launching","text":"Basic usage of @parallel_for/@parallel_reduce macros implies that the user only needs to define the kernel function and then launch it with the desired range and arguments. Thus, completely abstracting away backend-specific details that are not necessarily portable.\n\nThe general format of a kernel launch is as follows:\n\nfunction kernel_function(i, args...)\n    # kernel code here\nend\n\nJACC.@parallel_for range=kernel_range kernel_function(args...)\nresult = JACC.@parallel_reduce range=kernel_range op=operator init=initial_value kernel_function(args...)\n\nExample of @parallel_for macro:\n\n\nfunction kernel_1D(i, args...)\n    # kernel code here\nend\n\nfunction kernel_2D(i, j, args...)\n    # kernel code here\nend\n\nfunction kernel_2D(i, j, k, args...)\n    # kernel code here\nend\n\nJACC.@parallel_for range=N kernel_1D(args...)\nJACC.@parallel_for range=(Nx, Ny) kernel_2D(args...)\nJACC.@parallel_for range=(Nx, Ny, Nz) kernel_3D(args...)\n\nExample of @parallel_reduce macro and convenience functions for sum reduction:\n\nimport JACC\nJACC.@init_backend\n\nN = 10 \nx = JACC.ones(Float32, N) \n\n# sum reduction over array x\nx_sum1 = JACC.@parallel_reduce range=N ((i,x)->x[i])(x)\n@show x_sum1\n\nfunction elem(i, x)\n    return x[i]\nend\n\nx_sum2 = JACC.@parallel_reduce range=N elem(x)\n@show x_sum2\n\n# convenience functions for sum (default) reduction\nx_sum3 = JACC.@parallel_reduce range=N JACC.elem_access(x)\n@show x_sum3\n\nx_sum4 = JACC.parallel_reduce(x)\n@show x_sum4\n\nOutput:\n\nx_sum1[] = 10.0\nx_sum2[] = 10.0\nx_sum3[] = 10.0\nx_sum4 = 10.0f0\n\n!!! warning \"@parallelreduce vs parallelreduce\" return types\n\nNote that the `@parallel_reduce` macro returns an array type, while the `parallel_reduce` convenience function returns the reduced value directly. Use the one that fits your needs.\n\nIn summary:\n\nJACC.@parallel_for range=kernel_range kernel_function(args...) requires a range and a kernel function with arguments.\nJACC.@parallel_reduce range=kernel_range op=operator init=initial_value kernel_function(args...) requires a range, an operator (+,*,min,max), an initial value, and a kernel function with arguments.\n\nConvenience functions for common reduction operations:\n\nred = JACC.parallel_reduce(a)\nred = JACC.parallel_reduce(op, a) with special op= +, *, min, max\nred = JACC.parallel_reduce(dims, dot, x1, x2) Special op=dot product reduction, requires two arrays x1, x2.","category":"section"},{"location":"api_usage/#Advanced-kernel-launching","page":"API Usage","title":"Advanced kernel launching","text":"JACC also provides advanced options for kernel launching, allowing users to specify additional parameters such as blocks/thread sizes (GPU only), shared memory usage, and more. These options can be passed as keyword arguments to the @parallel_for and @parallel_reduce macros.\n\nJACC.@parallel_for range=kernel_range blocks= blocks threads=threads shmem_size=shmem_size sync=true stream=stream_handler kernel_function(args...)\n\nwhere the additional parameters are:\n\nblocks: number of blocks (GPU only)\nthreads: number of threads per block (GPU only)\nshmem_size: size of shared memory to allocate in KB (GPU only)\nstream: stream identifier (GPU only), handler from JACC.default_stream() or JACC.create_stream() see AMD GPU tests\nsync: true or false, whether to synchronize after kernel launch (default: true)\n\nJACC.@parallel_reduce range=kernel_range op=operator init=initial_value blocks=blocks threads=threads  sync=true stream=stream_handler kernel_function(args...)\n\nwhere the additional parameters are:\n\nblocks: number of blocks (GPU only)\nthreads: number of threads per block (GPU only)\nstream: stream identifier (GPU only), handler from JACC.default_stream() or JACC.create_stream() see AMD GPU tests\nsync: true or false, whether to synchronize after kernel launch (default: true)\n\nOther examples and more advanced usages can be found in the JACC tests directory","category":"section"},{"location":"#JACC-Introduction","page":"Welcome","title":"JACC Introduction","text":"JACC.jl is a Julia package for performance portable CPU/GPU kernels using metaprogramming on top of existing Julia backends. It enables users to write a single code based on an array memory model and parallel_for and parallel_reduce functions that can run on both CPUs and GPUs without needing to rewrite the code for each platform.\n\nwhy: Who can benefit with JACC?\nScientists and engineers can benefit from JACC's default basic APIs that enable minimal effort to access CPU and GPU parallel capabilities to accelerate codes and let users focus on their algorithms and science. Advanced users can also access low-level backend specific features (e.g., blocks/threads and synchronization) when needed. \n\n(Image: parallel_for)\n\nAs shown in the schematics, parallel_for (and parallel_reduce) constructs are functional forms of for-loops that can be executed in parallel on multiple processing units (e.g., CPU cores, GPU threads). They allow users to express parallelism in their code without dealing with low-level threading or synchronization details across vendor architectures. JACC provides a unified API to launch parallel workloads on different back ends (CPU/GPU) without changing the user's code.\n\nWhile the JuliaGPU ecosystem provides powerful tools for GPU programming, JACC sits on top of these backends leveraging these capabilities to simplify the process of writing portable code that can run on both CPUs and GPUs without modification. Thus filling a gap in the Julia ecosystem for productive, high-level programming for performance portability across heterogeneous computing platforms.\n\nJACC architecture overview:\n\n(Image: JACC Architecture)\n\nResources:\n\nFor a broader understanding of JACC's design principles and goals, please refer to the JACC paper at SC-W 2024 - open version available here.\nFor a full example using JACC, see the Gray-Scott code and \"Julia for HPC\" Tutorial material","category":"section"},{"location":"#Why-Julia?","page":"Welcome","title":"Why Julia?","text":"Julia enables scientists and engineers to write code more quickly and to focus on their science or technical domain. \n\nJulia combines high-level/low-level capabilities for easy to read and write code due to its expressive mathematical syntax (e.g. arrays, GPU programming, parallelization). \nJulia's just-in-time (JIT) compilation based on LLVM allows for speeds comparable to C, C++ or Fortran.\nJulia's unified package manager, Pkg.jl, simplifies the process of managing dependencies.\nJulia's rich ecosystem includes a wide range of libraries and tools for scientific computing, data analysis, and machine learning.","category":"section"},{"location":"#Supported-backends","page":"Welcome","title":"Supported backends","text":"CPU (default):\nThreads: multi-threading on CPU using Julia's built-in threading capabilities.\nGPU from JuliaGPU:\nCUDA: NVIDIA GPUs using the CUDA.jl package.\nAMDGPU: AMD GPUs using the AMDGPU.jl package.\nMetal: Apple Silicon GPUs using the Metal.jl package.\noneAPI: Intel GPUs using the oneAPI.jl package (Experimental).","category":"section"},{"location":"#Installation","page":"Welcome","title":"Installation","text":"JACC is a registered Julia package. Install JACC using Julia's Pkg.jl capabilities for managing packages.  e.g.\n\nInstallation from the Julia REPL:\n\njulia> ]\npkg> add JACC\n\nfrom command line (e.g. CI):\n\njulia -e 'using Pkg; Pkg.add(\"JACC\")'","category":"section"},{"location":"#Quick-start-filling-and-reducing-an-array","page":"Welcome","title":"Quick start - filling and reducing an array","text":"Prerequisite: \n\nJulia 1.11 or later\n\nTo run an example from scratch\n\nInstall JACC.jl\n\njulia -e 'using Pkg; Pkg.add(\"JACC\")'\n\nCopy this file to your local machine and save it as jacc-saxpy.jl:\n\nimport JACC\nJACC.@init_backend\n\nfunction axpy(i, alpha, x, y)\n    @inbounds x[i] += alpha * y[i]\nend\n\nN = 10\nalpha = Float32(2.0)\nx = JACC.zeros(Float32, N)\ny = JACC.array(fill(Float32(5), N))\nJACC.@parallel_for range=N axpy(alpha, x, y)\n@show x\nx_sum = JACC.parallel_reduce(x)\n@show x_sum\n\nRun the example using the default Threads back end with 4 threads:\n\njulia -t 4 jacc-saxpy.jl\n\nSwitch to another backend, e.g. assuming access to NVIDIA GPU and that CUDA is installed and configured:\n\njulia -e 'using JACC; JACC.set_backend(\"CUDA\")'\n\nnote: Note\nThis step might take a while the first time downloading all CUDA.jl dependencies. After installation please refer to CUDA.jl docs if wanting to use a local CUDA installation.\n\nnote: Note\nMac users can use the \"Metal\" backend for Float32 computations as Float64 is not supported on Apple Silicon GPUs. To set the Metal backend use JACC.set_backend(\"Metal\").\n\nRun the example again, but this time the same code will run on the GPU:\n\njulia jacc-saxpy.jl","category":"section"}]
}
